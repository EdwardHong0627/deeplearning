{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡開始已經假設你已經看過前面的所有基礎文件說明，因此多數註解會拿掉以維護版面乾淨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception是一個不同於AlexNet、VGG思維的架構，他不以取深，而取寬，讓模型自己學習要怎麼取特徵，很特別，別具一格，並且以更少的參數得到更好的結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型不會特定從v1一路弄到v3，有最新的就取最新就好了，不直接v4是因為v4加入resnet的概念，因此一步一步實作瞭解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下已有翻譯Inception論文，也可以參閱[相關文件](https://hackmd.io/@shaoeChen/SyjI6W2zB/https%3A%2F%2Fhackmd.io%2F%40shaoeChen%2FrkIGBzWEI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先載入相關需求套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定硬體資源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料集的部份是使用ImageNet訓練，不過這部份在下就只提供[資料集連結](http://www.image-net.org/)，不然硬train一發怕時間太久。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從論文中我們知道：\n",
    "* inception的每一個block是堆出來的，它由機器自己學習要用什麼樣的filter來抽取特徵\n",
    "* inception的每一層都是conv -> bn，因此實作上我們會把這個寫成一個function，減少重覆的程式碼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception已經無法再使用單純的`tf.keras.models.Sequential`來逐層建構模型，因此要採用其它的方式，class或function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用標準的keras function來建置模型，範例參考[keras application](https://github.com/keras-team/keras-applications/blob/master/keras_applications/inception_v3.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x, \n",
    "            filter_num, \n",
    "            filter_row, \n",
    "            filter_col,\n",
    "            padding='same', \n",
    "            strides=1, \n",
    "            name=None):\n",
    "    \"\"\"conv layer\n",
    "    每一個卷積後面都會加上BN，然後再經過ReLU\n",
    "    \n",
    "    parameters:\n",
    "        x: input\n",
    "        filter_num: filter的數量\n",
    "        filter_row: filter的row\n",
    "        filter_col: filter的col\n",
    "        padding: padding的方式\n",
    "        strides: 卷積的步幅，假設都是nxn\n",
    "        name: 這一層的名稱，盡可能的設置，後續繪製出圖形的時候比較能夠理解自己的模型\n",
    "    \n",
    "    return:\n",
    "        回傳經過卷積、BN、ReLE的結果\n",
    "        \n",
    "    remark:\n",
    "        如果有想要設置更多參數就上下加入相對應參數即可\n",
    "    \"\"\"\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(\n",
    "            filters=filter_num,\n",
    "            kernel_size=(filter_row, filter_col),\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            name=conv_name)(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name=bn_name)(x)\n",
    "    x = tf.keras.layers.Activation('relu', name=name)(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的程式碼非常直覺瞭解，就是將輸入經過conv、bn、relu計算之後回傳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我們開始建構inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception():\n",
    "    # 如果你有需要可以將input shape做為參數\n",
    "    # 但相信你的專案在建置的時候已經確定其維度，因此這邊會直接寫死\n",
    "    \n",
    "    img_input = tf.keras.layers.Input(shape=(299, 299, 3))\n",
    "    \n",
    "    # 先利用標準的CNN架構做了兩次的MaxPooling將維度縮小\n",
    "    x = conv_bn(img_input, 32, 3, 3, padding='valid', strides=2, name='layer_1')\n",
    "    x = conv_bn(x, 32, 3, 3, padding='valid', name='layer_2')\n",
    "    x = conv_bn(x, 64, 3, 3, name='layer_3')\n",
    "    x = tf.keras.layers.MaxPool2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    x = conv_bn(x, 80, 1, 1, padding='valid', name='layer_4')\n",
    "    x = conv_bn(x, 192, 3, 3, padding='valid', name='layer_5')\n",
    "    x = tf.keras.layers.MaxPool2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # 第一個區塊\n",
    "    # 區塊內總共含有四個feature extraction的方法\n",
    "    # 這四種方法我們可以發現到它們的input都是x\n",
    "    # 這代表模型會將同一個輸入x做多種不同的特徵提取\n",
    "    # 首先是1x1\n",
    "    branch1x1 = conv_bn(x, 64, 1, 1, name='b1_1x1')\n",
    "    \n",
    "    # 接下來是5x5\n",
    "    branch5x5 = conv_bn(x, 48, 1, 1, name='b1_5x5_1')\n",
    "    branch5x5 = conv_bn(branch5x5, 64, 5, 5, name='b1_5x5_2')\n",
    "    \n",
    "    # 然後是3x3\n",
    "    branch3x3 = conv_bn(x, 64, 1, 1, name='b1_3x3_1')\n",
    "    branch3x3 = conv_bn(branch3x3, 96, 3, 3, name='b1_3x3_2')\n",
    "    branch3x3 = conv_bn(branch3x3, 96, 3, 3, name='b1_3x3_3')\n",
    "    \n",
    "    # 最後是pool\n",
    "    branch_pool = tf.keras.layers.AveragePooling2D((3, 3),\n",
    "                                                   strides=(1, 1),\n",
    "                                                   padding='same')(x)\n",
    "    \n",
    "    branch_pool = conv_bn(branch_pool, 64, 1, 1, name='b1_pool')\n",
    "    \n",
    "    # 將四個feature extract之後的資料堆疊做為output\n",
    "    # 裡面含有四種口味的特徵\n",
    "    # axis=3代表我們要依著channel這個軸來堆疊\n",
    "    # 堆疊過程中最重要的就是維度的確認\n",
    "    # 以這個區塊來說，最終的hxw為35x35，因此你必需確保你的每一個方法的output都是35x35，否則會報錯\n",
    "    x = tf.keras.layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed1'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    model = tf.keras.models.Model(img_input, x, name='inception_v3')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們可以先堆疊一個區塊，然後利用`summary`來驗證模型維度是否跟我們所想的一樣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_conv (Conv2D)           (None, 149, 149, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_bn (BatchNormalization) (None, 149, 149, 32) 128         layer_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_1 (Activation)            (None, 149, 149, 32) 0           layer_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_conv (Conv2D)           (None, 147, 147, 32) 9248        layer_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_bn (BatchNormalization) (None, 147, 147, 32) 128         layer_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_2 (Activation)            (None, 147, 147, 32) 0           layer_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_3_conv (Conv2D)           (None, 147, 147, 64) 18496       layer_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_3_bn (BatchNormalization) (None, 147, 147, 64) 256         layer_3_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_3 (Activation)            (None, 147, 147, 64) 0           layer_3_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           layer_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_4_conv (Conv2D)           (None, 73, 73, 80)   5200        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_4_bn (BatchNormalization) (None, 73, 73, 80)   320         layer_4_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_4 (Activation)            (None, 73, 73, 80)   0           layer_4_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_5_conv (Conv2D)           (None, 71, 71, 192)  138432      layer_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_5_bn (BatchNormalization) (None, 71, 71, 192)  768         layer_5_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_5 (Activation)            (None, 71, 71, 192)  0           layer_5_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           layer_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_1_conv (Conv2D)          (None, 35, 35, 64)   12352       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_1_bn (BatchNormalization (None, 35, 35, 64)   256         b1_3x3_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_1 (Activation)           (None, 35, 35, 64)   0           b1_3x3_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b1_5x5_1_conv (Conv2D)          (None, 35, 35, 48)   9264        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_2_conv (Conv2D)          (None, 35, 35, 96)   55392       b1_3x3_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b1_5x5_1_bn (BatchNormalization (None, 35, 35, 48)   192         b1_5x5_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_2_bn (BatchNormalization (None, 35, 35, 96)   384         b1_3x3_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b1_5x5_1 (Activation)           (None, 35, 35, 48)   0           b1_5x5_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_2 (Activation)           (None, 35, 35, 96)   0           b1_3x3_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b1_1x1_conv (Conv2D)            (None, 35, 35, 64)   12352       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b1_5x5_2_conv (Conv2D)          (None, 35, 35, 64)   76864       b1_5x5_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_3_conv (Conv2D)          (None, 35, 35, 96)   83040       b1_3x3_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b1_pool_conv (Conv2D)           (None, 35, 35, 64)   12352       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "b1_1x1_bn (BatchNormalization)  (None, 35, 35, 64)   256         b1_1x1_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b1_5x5_2_bn (BatchNormalization (None, 35, 35, 64)   256         b1_5x5_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_3_bn (BatchNormalization (None, 35, 35, 96)   384         b1_3x3_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b1_pool_bn (BatchNormalization) (None, 35, 35, 64)   256         b1_pool_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b1_1x1 (Activation)             (None, 35, 35, 64)   0           b1_1x1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b1_5x5_2 (Activation)           (None, 35, 35, 64)   0           b1_5x5_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_3 (Activation)           (None, 35, 35, 96)   0           b1_3x3_3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b1_pool (Activation)            (None, 35, 35, 64)   0           b1_pool_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           b1_1x1[0][0]                     \n",
      "                                                                 b1_5x5_2[0][0]                   \n",
      "                                                                 b1_3x3_3[0][0]                   \n",
      "                                                                 b1_pool[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 437,472\n",
      "Trainable params: 435,680\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從模型資訊可以看的到，最終我們得到的是一個35x35x288的輸出，這代表第一個區塊之後我們有288個35x35的filter，而這288個filter是由四種不同的特徵提取方法學習而得。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這種作法的好處在於即使深，它的總參數量還是比VGG16、AlexNet還要來的少太多太多，而且效能還不輸。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讓我們將整個模型建置完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception():\n",
    "    # 如果你有需要可以將input shape做為參數\n",
    "    # 但相信你的專案在建置的時候已經確定其維度，因此這邊會直接寫死\n",
    "    \n",
    "    img_input = tf.keras.layers.Input(shape=(299, 299, 3))\n",
    "    \n",
    "    # 先利用標準的CNN架構做了兩次的MaxPooling將維度縮小\n",
    "    x = conv_bn(img_input, 32, 3, 3, padding='valid', strides=2, name='layer_1')\n",
    "    x = conv_bn(x, 32, 3, 3, padding='valid', name='layer_2')\n",
    "    x = conv_bn(x, 64, 3, 3, name='layer_3')\n",
    "    x = tf.keras.layers.MaxPool2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    x = conv_bn(x, 80, 1, 1, padding='valid', name='layer_4')\n",
    "    x = conv_bn(x, 192, 3, 3, padding='valid', name='layer_5')\n",
    "    x = tf.keras.layers.MaxPool2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # 第一個區塊 35x38x288\n",
    "    # 區塊內總共含有四個feature extraction的方法\n",
    "    # 這四種方法我們可以發現到它們的input都是x\n",
    "    # 這代表模型會將同一個輸入x做多種不同的特徵提取\n",
    "    # 首先是1x1\n",
    "    branch1x1 = conv_bn(x, 64, 1, 1, name='b1_1x1')\n",
    "    \n",
    "    # 接下來是5x5\n",
    "    branch5x5 = conv_bn(x, 48, 1, 1, name='b1_5x5_1')\n",
    "    branch5x5 = conv_bn(branch5x5, 64, 5, 5, name='b1_5x5_2')\n",
    "    \n",
    "    # 然後是3x3\n",
    "    branch3x3 = conv_bn(x, 64, 1, 1, name='b1_3x3_1')\n",
    "    branch3x3 = conv_bn(branch3x3, 96, 3, 3, name='b1_3x3_2')\n",
    "    branch3x3 = conv_bn(branch3x3, 96, 3, 3, name='b1_3x3_3')\n",
    "    \n",
    "    # 最後是pool\n",
    "    branch_pool = tf.keras.layers.AveragePooling2D((3, 3),\n",
    "                                                   strides=(1, 1),\n",
    "                                                   padding='same')(x)\n",
    "    \n",
    "    branch_pool = conv_bn(branch_pool, 64, 1, 1, name='b1_pool')\n",
    "    \n",
    "    # 將四個feature extract之後的資料堆疊做為output\n",
    "    # 裡面含有四種口味的特徵\n",
    "    # axis=3代表我們要依著channel這個軸來堆疊\n",
    "    # 堆疊過程中最重要的就是維度的確認\n",
    "    # 以這個區塊來說，最終的hxw為35x35，因此你必需確保你的每一個方法的output都是35x35，否則會報錯    \n",
    "    x = tf.keras.layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed1'\n",
    "    )\n",
    "    \n",
    "    # 第二個區塊 35x35x288\n",
    "    # 其實應該是可以用迴圈跟第一個區塊寫在一起\n",
    "    # 首先是1x1\n",
    "    branch1x1 = conv_bn(x, 64, 1, 1, name='b2_1x1')\n",
    "    \n",
    "    # 接下來是5x5\n",
    "    branch5x5 = conv_bn(x, 48, 1, 1, name='b2_5x5_1')\n",
    "    branch5x5 = conv_bn(branch5x5, 64, 5, 5, name='b2_5x5_2')\n",
    "    \n",
    "    # 然後是3x3\n",
    "    branch3x3 = conv_bn(x, 64, 1, 1, name='b2_3x3_1')\n",
    "    branch3x3 = conv_bn(branch3x3, 96, 3, 3, name='b2_3x3_2')\n",
    "    branch3x3 = conv_bn(branch3x3, 96, 3, 3, name='b2_3x3_3')\n",
    "    \n",
    "    # 最後是pool\n",
    "    branch_pool = tf.keras.layers.AveragePooling2D((3, 3),\n",
    "                                                   strides=(1, 1),\n",
    "                                                   padding='same')(x)\n",
    "    \n",
    "    branch_pool = conv_bn(branch_pool, 64, 1, 1, name='b2_pool')\n",
    "    \n",
    "    # 將四個feature extract之後的資料堆疊做為output    \n",
    "    x = tf.keras.layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed2'\n",
    "    )        \n",
    "    \n",
    "    # 第三個區塊 17x17x768\n",
    "    # 首先是3x3\n",
    "    branch3x3_1 = conv_bn(x, 384, 3, 3, strides=2, padding='valid', name='b3_3x3_1')\n",
    "    \n",
    "    # 接下來是3x3\n",
    "    branch3x3_2 = conv_bn(x, 64, 1, 1, name='b3_3x3_2_1')\n",
    "    branch3x3_2 = conv_bn(branch3x3_2, 96, 3, 3, name='b3_3x3_2_2')\n",
    "    branch3x3_2 = conv_bn(branch3x3_2, 96, 3, 3, strides=2, padding='valid', name='b3_3x3_2_3')\n",
    "    \n",
    "    # 最後是pool\n",
    "    branch_pool = tf.keras.layers.MaxPooling2D((3, 3),\n",
    "                                               strides=(2, 2))(x)    \n",
    "    \n",
    "    # 將四個feature extract之後的資料堆疊做為output    \n",
    "    x = tf.keras.layers.concatenate(\n",
    "        [branch3x3_1, branch3x3_2, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed3'\n",
    "    )   \n",
    "    \n",
    "    # 第四個區塊 17x17x768\n",
    "    # 首先是1x1\n",
    "    branch1x1 = conv_bn(x, 192, 1, 1, name='b4_1x1')    \n",
    "    \n",
    "    # 接下來是7x7\n",
    "    branch7x7_1 = conv_bn(x, 128, 1, 1, name='b4_7x7_1_1')\n",
    "    branch7x7_1 = conv_bn(branch7x7_1, 128, 1, 7, name='b4_7x7_1_2')\n",
    "    branch7x7_1 = conv_bn(branch7x7_1, 192, 7, 1, name='b4_7x7_1_3')\n",
    "    \n",
    "    # 然後是7x7\n",
    "    branch7x7_2 = conv_bn(x, 128, 1, 1, name='b4_7x7_2_1')\n",
    "    branch7x7_2 = conv_bn(branch7x7_2, 128, 7, 1, name='b4_7x7_2_2')\n",
    "    branch7x7_2 = conv_bn(branch7x7_2, 128, 1, 7, name='b4_7x7_2_3')\n",
    "    branch7x7_2 = conv_bn(branch7x7_2, 128, 7, 1, name='b4_7x7_2_4')\n",
    "    branch7x7_2 = conv_bn(branch7x7_2, 192, 1, 7, name='b4_7x7_2_5')\n",
    "    \n",
    "    # 最後是pool\n",
    "    branch_pool = tf.keras.layers.AveragePooling2D((3, 3),\n",
    "                                                   strides=(1, 1),\n",
    "                                                   padding='same')(x)\n",
    "    \n",
    "    branch_pool = conv_bn(branch_pool, 192, 1, 1, name='b4_pool')\n",
    "    \n",
    "    # 將四個feature extract之後的資料堆疊做為output    \n",
    "    x = tf.keras.layers.concatenate(\n",
    "        [branch1x1, branch7x7_1, branch7x7_2, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed4'\n",
    "    ) \n",
    "    \n",
    "    # 第五、六個區塊 17x17x768\n",
    "    for i in range(2):\n",
    "        # 首先是1x1\n",
    "        branch1x1 = conv_bn(x, 192, 1, 1, name='b' + str(5 + i) + '_1x1')    \n",
    "\n",
    "        # 接下來是7x7\n",
    "        branch7x7_1 = conv_bn(x, 128, 1, 1, name='b' + str(5 + i) + '_7x7_1_1')\n",
    "        branch7x7_1 = conv_bn(branch7x7_1, 128, 1, 7, name='b' + str(5 + i) + '_7x7_1_2')\n",
    "        branch7x7_1 = conv_bn(branch7x7_1, 192, 7, 1, name='b' + str(5 + i) + '_7x7_1_3')\n",
    "\n",
    "        # 然後是7x7\n",
    "        branch7x7_2 = conv_bn(x, 128, 1, 1, name='b' + str(5 + i) + '_7x7_2_1')\n",
    "        branch7x7_2 = conv_bn(branch7x7_2, 128, 7, 1, name='b' + str(5 + i) + '_7x7_2_2')\n",
    "        branch7x7_2 = conv_bn(branch7x7_2, 128, 1, 7, name='b' + str(5 + i) + '_7x7_2_3')\n",
    "        branch7x7_2 = conv_bn(branch7x7_2, 192, 7, 1, name='b' + str(5 + i) + '_7x7_2_4')\n",
    "        branch7x7_2 = conv_bn(branch7x7_2, 192, 1, 7, name='b' + str(5 + i) + '_7x7_2_5')\n",
    "\n",
    "        # 最後是pool\n",
    "        branch_pool = tf.keras.layers.AveragePooling2D((3, 3),\n",
    "                                                       strides=(1, 1),\n",
    "                                                       padding='same')(x)\n",
    "\n",
    "        branch_pool = conv_bn(branch_pool, 192, 1, 1, name='b' + str(5 + i) + '_pool') \n",
    "        \n",
    "        # 將四個feature extract之後的資料堆疊做為output    \n",
    "        x = tf.keras.layers.concatenate(\n",
    "            [branch1x1, branch7x7_1, branch7x7_2, branch_pool],\n",
    "            axis=3,\n",
    "            name='mixed' + str(5 + i)\n",
    "        )   \n",
    "    \n",
    "    # 第七個區塊 17x17x768\n",
    "    # 首先是1x1\n",
    "    branch1x1 = conv_bn(x, 192, 1, 1, name='b7_1x1')    \n",
    "    \n",
    "    # 接下來是7x7\n",
    "    branch7x7_1 = conv_bn(x, 192, 1, 1, name='b7_7x7_1_1')\n",
    "    branch7x7_1 = conv_bn(branch7x7_1, 192, 1, 7, name='b7_7x7_1_2')\n",
    "    branch7x7_1 = conv_bn(branch7x7_1, 192, 7, 1, name='b7_7x7_1_3')    \n",
    "   \n",
    "    # 然後是7x7\n",
    "    branch7x7_2 = conv_bn(x, 192, 1, 1, name='b7_7x7_2_1')\n",
    "    branch7x7_2 = conv_bn(branch7x7_2, 192, 7, 1, name='b7_7x7_2_2')\n",
    "    branch7x7_2 = conv_bn(branch7x7_2, 192, 1, 7, name='b7_7x7_2_3')\n",
    "    branch7x7_2 = conv_bn(branch7x7_2, 192, 7, 1, name='b7_7x7_2_4')\n",
    "    branch7x7_2 = conv_bn(branch7x7_2, 192, 1, 7, name='b7_7x7_2_5')    \n",
    "    # 最後是pool\n",
    "    branch_pool = tf.keras.layers.AveragePooling2D((3, 3),\n",
    "                                                   strides=(1, 1),\n",
    "                                                   padding='same')(x)\n",
    "\n",
    "    branch_pool = conv_bn(branch_pool, 192, 1, 1, name='b7_pool')     \n",
    "    # 將四個feature extract之後的資料堆疊做為output    \n",
    "    x = tf.keras.layers.concatenate(\n",
    "        [branch1x1, branch7x7_1, branch7x7_2, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed7' \n",
    "    )  \n",
    "        \n",
    "        \n",
    "    # 第八個區塊 8x8x1200\n",
    "    # 首先是3x3\n",
    "    branch3x3 = conv_bn(x, 192, 1, 1, name='b8_3x3_1')\n",
    "    branch3x3 = conv_bn(branch3x3, 320, 3, 3, strides=2, padding='valid', name='b8_3x3_2')\n",
    "    \n",
    "    # 接下來是7x7\n",
    "    branch7x7 = conv_bn(x, 192, 1, 1, name='b8_7x7_1')\n",
    "    branch7x7 = conv_bn(branch7x7, 192, 1, 7, name='b8_7x7_2')\n",
    "    branch7x7 = conv_bn(branch7x7, 192, 7, 1, name='b8_7x7_3')\n",
    "    branch7x7 = conv_bn(branch7x7, 192, 3, 3, strides=2, padding='valid', name='b8_7x7_4')\n",
    "    \n",
    "    # 最後是pool\n",
    "    branch_pool = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = tf.keras.layers.concatenate(\n",
    "        [branch3x3, branch7x7, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed8'\n",
    "    )\n",
    "    \n",
    "    # 第九、十個區塊 8x8x2048\n",
    "    for i in range(2):\n",
    "        # 首先是1x1\n",
    "        branch1x1 = conv_bn(x, 320, 1, 1, name='b' + str(9 + i) + '_1x1')    \n",
    "        \n",
    "        # 接下來是3x3\n",
    "        branch3x3_1 = conv_bn(x, 384, 1, 1, name='b' + str(9 + i) + '_3x3_1')\n",
    "        # 下面要注意的是，它是將3x3之後的output再分別經過1x3、3x1，然後再堆起來\n",
    "        branch3x3_1_1 = conv_bn(branch3x3_1, 384, 1, 3, name='b' + str(9 + i) + '_3x3_1_1')\n",
    "        branch3x3_1_2 = conv_bn(branch3x3_1, 384, 3, 1, name='b' + str(9 + i) + '_3x3_1_2')\n",
    "        branch3x3_1 = tf.keras.layers.concatenate(\n",
    "            [branch3x3_1_1, branch3x3_1_2],\n",
    "            axis=3,\n",
    "            name='mixed' + str(9 + i ) + '_1_' + str(i)\n",
    "        )\n",
    "\n",
    "        # 然後是3x3\n",
    "        branch3x3_2 = conv_bn(x, 448, 1, 1, name='b' + str(9 + i) + '_3x3_2_1')\n",
    "        branch3x3_2 = conv_bn(branch3x3_2, 384, 1, 1, name='b' + str(9 + i) + '_3x3_2_2')\n",
    "        # 下面要注意的是，它是將3x3之後的output再分別經過1x3、3x1，然後再堆起來\n",
    "        branch3x3_2_1 = conv_bn(branch3x3_2, 384, 1, 3, name='b' + str(9 + i) + '_3x3_21')\n",
    "        branch3x3_2_2 = conv_bn(branch3x3_2, 384, 3, 1, name='b' + str(9 + i) + '_3x3_22')\n",
    "        branch3x3_2 = tf.keras.layers.concatenate(\n",
    "            [branch3x3_2_1, branch3x3_2_2],\n",
    "            axis=3,\n",
    "            name='mixed' + str(9 + i ) + '_2_' + str(i)\n",
    "        )\n",
    "        \n",
    "        # 最後是pool\n",
    "        branch_pool = tf.keras.layers.AveragePooling2D((3, 3),\n",
    "                                                       strides=(1, 1),\n",
    "                                                       padding='same')(x)\n",
    "\n",
    "        branch_pool = conv_bn(branch_pool, 192, 1, 1, name='b' + str(9 + i) + '_pool') \n",
    "        \n",
    "        # 將四個feature extract之後的資料堆疊做為output    \n",
    "        x = tf.keras.layers.concatenate(\n",
    "            [branch1x1, branch3x3_1, branch3x3_2, branch_pool],\n",
    "            axis=3,\n",
    "            name='mixed' + str(9 + i)\n",
    "        )         \n",
    "        \n",
    "    # 然後是global average pooling或global max pooling\n",
    "    # inception並沒有接fully connected layer，這大大減少了參數量\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name='g_avg_pool')(x)\n",
    "    x = tf.keras.layers.Dense(1000, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(img_input, x, name='inception_v3')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_conv (Conv2D)           (None, 149, 149, 32) 896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_bn (BatchNormalization) (None, 149, 149, 32) 128         layer_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_1 (Activation)            (None, 149, 149, 32) 0           layer_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_conv (Conv2D)           (None, 147, 147, 32) 9248        layer_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_bn (BatchNormalization) (None, 147, 147, 32) 128         layer_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_2 (Activation)            (None, 147, 147, 32) 0           layer_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_3_conv (Conv2D)           (None, 147, 147, 64) 18496       layer_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_3_bn (BatchNormalization) (None, 147, 147, 64) 256         layer_3_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_3 (Activation)            (None, 147, 147, 64) 0           layer_3_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 73, 73, 64)   0           layer_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_4_conv (Conv2D)           (None, 73, 73, 80)   5200        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_4_bn (BatchNormalization) (None, 73, 73, 80)   320         layer_4_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_4 (Activation)            (None, 73, 73, 80)   0           layer_4_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_5_conv (Conv2D)           (None, 71, 71, 192)  138432      layer_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_5_bn (BatchNormalization) (None, 71, 71, 192)  768         layer_5_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_5 (Activation)            (None, 71, 71, 192)  0           layer_5_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 35, 35, 192)  0           layer_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_1_conv (Conv2D)          (None, 35, 35, 64)   12352       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_1_bn (BatchNormalization (None, 35, 35, 64)   256         b1_3x3_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_1 (Activation)           (None, 35, 35, 64)   0           b1_3x3_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b1_5x5_1_conv (Conv2D)          (None, 35, 35, 48)   9264        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_2_conv (Conv2D)          (None, 35, 35, 96)   55392       b1_3x3_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b1_5x5_1_bn (BatchNormalization (None, 35, 35, 48)   192         b1_5x5_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_2_bn (BatchNormalization (None, 35, 35, 96)   384         b1_3x3_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b1_5x5_1 (Activation)           (None, 35, 35, 48)   0           b1_5x5_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_2 (Activation)           (None, 35, 35, 96)   0           b1_3x3_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b1_1x1_conv (Conv2D)            (None, 35, 35, 64)   12352       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b1_5x5_2_conv (Conv2D)          (None, 35, 35, 64)   76864       b1_5x5_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_3_conv (Conv2D)          (None, 35, 35, 96)   83040       b1_3x3_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b1_pool_conv (Conv2D)           (None, 35, 35, 64)   12352       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "b1_1x1_bn (BatchNormalization)  (None, 35, 35, 64)   256         b1_1x1_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b1_5x5_2_bn (BatchNormalization (None, 35, 35, 64)   256         b1_5x5_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_3_bn (BatchNormalization (None, 35, 35, 96)   384         b1_3x3_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b1_pool_bn (BatchNormalization) (None, 35, 35, 64)   256         b1_pool_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b1_1x1 (Activation)             (None, 35, 35, 64)   0           b1_1x1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b1_5x5_2 (Activation)           (None, 35, 35, 64)   0           b1_5x5_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b1_3x3_3 (Activation)           (None, 35, 35, 96)   0           b1_3x3_3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b1_pool (Activation)            (None, 35, 35, 64)   0           b1_pool_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           b1_1x1[0][0]                     \n",
      "                                                                 b1_5x5_2[0][0]                   \n",
      "                                                                 b1_3x3_3[0][0]                   \n",
      "                                                                 b1_pool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b2_3x3_1_conv (Conv2D)          (None, 35, 35, 64)   18496       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b2_3x3_1_bn (BatchNormalization (None, 35, 35, 64)   256         b2_3x3_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b2_3x3_1 (Activation)           (None, 35, 35, 64)   0           b2_3x3_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b2_5x5_1_conv (Conv2D)          (None, 35, 35, 48)   13872       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b2_3x3_2_conv (Conv2D)          (None, 35, 35, 96)   55392       b2_3x3_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b2_5x5_1_bn (BatchNormalization (None, 35, 35, 48)   192         b2_5x5_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b2_3x3_2_bn (BatchNormalization (None, 35, 35, 96)   384         b2_3x3_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b2_5x5_1 (Activation)           (None, 35, 35, 48)   0           b2_5x5_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b2_3x3_2 (Activation)           (None, 35, 35, 96)   0           b2_3x3_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b2_1x1_conv (Conv2D)            (None, 35, 35, 64)   18496       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b2_5x5_2_conv (Conv2D)          (None, 35, 35, 64)   76864       b2_5x5_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b2_3x3_3_conv (Conv2D)          (None, 35, 35, 96)   83040       b2_3x3_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b2_pool_conv (Conv2D)           (None, 35, 35, 64)   18496       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "b2_1x1_bn (BatchNormalization)  (None, 35, 35, 64)   256         b2_1x1_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b2_5x5_2_bn (BatchNormalization (None, 35, 35, 64)   256         b2_5x5_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b2_3x3_3_bn (BatchNormalization (None, 35, 35, 96)   384         b2_3x3_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b2_pool_bn (BatchNormalization) (None, 35, 35, 64)   256         b2_pool_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b2_1x1 (Activation)             (None, 35, 35, 64)   0           b2_1x1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b2_5x5_2 (Activation)           (None, 35, 35, 64)   0           b2_5x5_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b2_3x3_3 (Activation)           (None, 35, 35, 96)   0           b2_3x3_3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b2_pool (Activation)            (None, 35, 35, 64)   0           b2_pool_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           b2_1x1[0][0]                     \n",
      "                                                                 b2_5x5_2[0][0]                   \n",
      "                                                                 b2_3x3_3[0][0]                   \n",
      "                                                                 b2_pool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b3_3x3_2_1_conv (Conv2D)        (None, 35, 35, 64)   18496       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b3_3x3_2_1_bn (BatchNormalizati (None, 35, 35, 64)   256         b3_3x3_2_1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b3_3x3_2_1 (Activation)         (None, 35, 35, 64)   0           b3_3x3_2_1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b3_3x3_2_2_conv (Conv2D)        (None, 35, 35, 96)   55392       b3_3x3_2_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b3_3x3_2_2_bn (BatchNormalizati (None, 35, 35, 96)   384         b3_3x3_2_2_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b3_3x3_2_2 (Activation)         (None, 35, 35, 96)   0           b3_3x3_2_2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b3_3x3_1_conv (Conv2D)          (None, 17, 17, 384)  995712      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b3_3x3_2_3_conv (Conv2D)        (None, 17, 17, 96)   83040       b3_3x3_2_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b3_3x3_1_bn (BatchNormalization (None, 17, 17, 384)  1536        b3_3x3_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b3_3x3_2_3_bn (BatchNormalizati (None, 17, 17, 96)   384         b3_3x3_2_3_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b3_3x3_1 (Activation)           (None, 17, 17, 384)  0           b3_3x3_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b3_3x3_2_3 (Activation)         (None, 17, 17, 96)   0           b3_3x3_2_3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           b3_3x3_1[0][0]                   \n",
      "                                                                 b3_3x3_2_3[0][0]                 \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_1_conv (Conv2D)        (None, 17, 17, 128)  98432       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_1_bn (BatchNormalizati (None, 17, 17, 128)  512         b4_7x7_2_1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_1 (Activation)         (None, 17, 17, 128)  0           b4_7x7_2_1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_2_conv (Conv2D)        (None, 17, 17, 128)  114816      b4_7x7_2_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_2_bn (BatchNormalizati (None, 17, 17, 128)  512         b4_7x7_2_2_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_2 (Activation)         (None, 17, 17, 128)  0           b4_7x7_2_2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_1_1_conv (Conv2D)        (None, 17, 17, 128)  98432       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_3_conv (Conv2D)        (None, 17, 17, 128)  114816      b4_7x7_2_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_1_1_bn (BatchNormalizati (None, 17, 17, 128)  512         b4_7x7_1_1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_3_bn (BatchNormalizati (None, 17, 17, 128)  512         b4_7x7_2_3_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_1_1 (Activation)         (None, 17, 17, 128)  0           b4_7x7_1_1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_3 (Activation)         (None, 17, 17, 128)  0           b4_7x7_2_3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_1_2_conv (Conv2D)        (None, 17, 17, 128)  114816      b4_7x7_1_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_4_conv (Conv2D)        (None, 17, 17, 128)  114816      b4_7x7_2_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_1_2_bn (BatchNormalizati (None, 17, 17, 128)  512         b4_7x7_1_2_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_4_bn (BatchNormalizati (None, 17, 17, 128)  512         b4_7x7_2_4_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_1_2 (Activation)         (None, 17, 17, 128)  0           b4_7x7_1_2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_4 (Activation)         (None, 17, 17, 128)  0           b4_7x7_2_4_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b4_1x1_conv (Conv2D)            (None, 17, 17, 192)  147648      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_1_3_conv (Conv2D)        (None, 17, 17, 192)  172224      b4_7x7_1_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_5_conv (Conv2D)        (None, 17, 17, 192)  172224      b4_7x7_2_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b4_pool_conv (Conv2D)           (None, 17, 17, 192)  147648      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "b4_1x1_bn (BatchNormalization)  (None, 17, 17, 192)  768         b4_1x1_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_1_3_bn (BatchNormalizati (None, 17, 17, 192)  768         b4_7x7_1_3_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_5_bn (BatchNormalizati (None, 17, 17, 192)  768         b4_7x7_2_5_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b4_pool_bn (BatchNormalization) (None, 17, 17, 192)  768         b4_pool_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b4_1x1 (Activation)             (None, 17, 17, 192)  0           b4_1x1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_1_3 (Activation)         (None, 17, 17, 192)  0           b4_7x7_1_3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b4_7x7_2_5 (Activation)         (None, 17, 17, 192)  0           b4_7x7_2_5_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b4_pool (Activation)            (None, 17, 17, 192)  0           b4_pool_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           b4_1x1[0][0]                     \n",
      "                                                                 b4_7x7_1_3[0][0]                 \n",
      "                                                                 b4_7x7_2_5[0][0]                 \n",
      "                                                                 b4_pool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_1_conv (Conv2D)        (None, 17, 17, 128)  98432       mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_1_bn (BatchNormalizati (None, 17, 17, 128)  512         b5_7x7_2_1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_1 (Activation)         (None, 17, 17, 128)  0           b5_7x7_2_1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_2_conv (Conv2D)        (None, 17, 17, 128)  114816      b5_7x7_2_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_2_bn (BatchNormalizati (None, 17, 17, 128)  512         b5_7x7_2_2_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_2 (Activation)         (None, 17, 17, 128)  0           b5_7x7_2_2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_1_1_conv (Conv2D)        (None, 17, 17, 128)  98432       mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_3_conv (Conv2D)        (None, 17, 17, 128)  114816      b5_7x7_2_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_1_1_bn (BatchNormalizati (None, 17, 17, 128)  512         b5_7x7_1_1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_3_bn (BatchNormalizati (None, 17, 17, 128)  512         b5_7x7_2_3_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_1_1 (Activation)         (None, 17, 17, 128)  0           b5_7x7_1_1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_3 (Activation)         (None, 17, 17, 128)  0           b5_7x7_2_3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_1_2_conv (Conv2D)        (None, 17, 17, 128)  114816      b5_7x7_1_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_4_conv (Conv2D)        (None, 17, 17, 192)  172224      b5_7x7_2_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_1_2_bn (BatchNormalizati (None, 17, 17, 128)  512         b5_7x7_1_2_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_4_bn (BatchNormalizati (None, 17, 17, 192)  768         b5_7x7_2_4_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_1_2 (Activation)         (None, 17, 17, 128)  0           b5_7x7_1_2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_4 (Activation)         (None, 17, 17, 192)  0           b5_7x7_2_4_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b5_1x1_conv (Conv2D)            (None, 17, 17, 192)  147648      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_1_3_conv (Conv2D)        (None, 17, 17, 192)  172224      b5_7x7_1_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_5_conv (Conv2D)        (None, 17, 17, 192)  258240      b5_7x7_2_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b5_pool_conv (Conv2D)           (None, 17, 17, 192)  147648      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "b5_1x1_bn (BatchNormalization)  (None, 17, 17, 192)  768         b5_1x1_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_1_3_bn (BatchNormalizati (None, 17, 17, 192)  768         b5_7x7_1_3_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_5_bn (BatchNormalizati (None, 17, 17, 192)  768         b5_7x7_2_5_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b5_pool_bn (BatchNormalization) (None, 17, 17, 192)  768         b5_pool_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b5_1x1 (Activation)             (None, 17, 17, 192)  0           b5_1x1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_1_3 (Activation)         (None, 17, 17, 192)  0           b5_7x7_1_3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b5_7x7_2_5 (Activation)         (None, 17, 17, 192)  0           b5_7x7_2_5_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b5_pool (Activation)            (None, 17, 17, 192)  0           b5_pool_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           b5_1x1[0][0]                     \n",
      "                                                                 b5_7x7_1_3[0][0]                 \n",
      "                                                                 b5_7x7_2_5[0][0]                 \n",
      "                                                                 b5_pool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_1_conv (Conv2D)        (None, 17, 17, 128)  98432       mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_1_bn (BatchNormalizati (None, 17, 17, 128)  512         b6_7x7_2_1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_1 (Activation)         (None, 17, 17, 128)  0           b6_7x7_2_1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_2_conv (Conv2D)        (None, 17, 17, 128)  114816      b6_7x7_2_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_2_bn (BatchNormalizati (None, 17, 17, 128)  512         b6_7x7_2_2_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_2 (Activation)         (None, 17, 17, 128)  0           b6_7x7_2_2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_1_1_conv (Conv2D)        (None, 17, 17, 128)  98432       mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_3_conv (Conv2D)        (None, 17, 17, 128)  114816      b6_7x7_2_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_1_1_bn (BatchNormalizati (None, 17, 17, 128)  512         b6_7x7_1_1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_3_bn (BatchNormalizati (None, 17, 17, 128)  512         b6_7x7_2_3_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_1_1 (Activation)         (None, 17, 17, 128)  0           b6_7x7_1_1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_3 (Activation)         (None, 17, 17, 128)  0           b6_7x7_2_3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_1_2_conv (Conv2D)        (None, 17, 17, 128)  114816      b6_7x7_1_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_4_conv (Conv2D)        (None, 17, 17, 192)  172224      b6_7x7_2_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_1_2_bn (BatchNormalizati (None, 17, 17, 128)  512         b6_7x7_1_2_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_4_bn (BatchNormalizati (None, 17, 17, 192)  768         b6_7x7_2_4_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_1_2 (Activation)         (None, 17, 17, 128)  0           b6_7x7_1_2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_4 (Activation)         (None, 17, 17, 192)  0           b6_7x7_2_4_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b6_1x1_conv (Conv2D)            (None, 17, 17, 192)  147648      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_1_3_conv (Conv2D)        (None, 17, 17, 192)  172224      b6_7x7_1_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_5_conv (Conv2D)        (None, 17, 17, 192)  258240      b6_7x7_2_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b6_pool_conv (Conv2D)           (None, 17, 17, 192)  147648      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "b6_1x1_bn (BatchNormalization)  (None, 17, 17, 192)  768         b6_1x1_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_1_3_bn (BatchNormalizati (None, 17, 17, 192)  768         b6_7x7_1_3_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_5_bn (BatchNormalizati (None, 17, 17, 192)  768         b6_7x7_2_5_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b6_pool_bn (BatchNormalization) (None, 17, 17, 192)  768         b6_pool_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b6_1x1 (Activation)             (None, 17, 17, 192)  0           b6_1x1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_1_3 (Activation)         (None, 17, 17, 192)  0           b6_7x7_1_3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b6_7x7_2_5 (Activation)         (None, 17, 17, 192)  0           b6_7x7_2_5_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b6_pool (Activation)            (None, 17, 17, 192)  0           b6_pool_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           b6_1x1[0][0]                     \n",
      "                                                                 b6_7x7_1_3[0][0]                 \n",
      "                                                                 b6_7x7_2_5[0][0]                 \n",
      "                                                                 b6_pool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_1_conv (Conv2D)        (None, 17, 17, 192)  147648      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_1_bn (BatchNormalizati (None, 17, 17, 192)  768         b7_7x7_2_1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_1 (Activation)         (None, 17, 17, 192)  0           b7_7x7_2_1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_2_conv (Conv2D)        (None, 17, 17, 192)  258240      b7_7x7_2_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_2_bn (BatchNormalizati (None, 17, 17, 192)  768         b7_7x7_2_2_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_2 (Activation)         (None, 17, 17, 192)  0           b7_7x7_2_2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_1_1_conv (Conv2D)        (None, 17, 17, 192)  147648      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_3_conv (Conv2D)        (None, 17, 17, 192)  258240      b7_7x7_2_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_1_1_bn (BatchNormalizati (None, 17, 17, 192)  768         b7_7x7_1_1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_3_bn (BatchNormalizati (None, 17, 17, 192)  768         b7_7x7_2_3_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_1_1 (Activation)         (None, 17, 17, 192)  0           b7_7x7_1_1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_3 (Activation)         (None, 17, 17, 192)  0           b7_7x7_2_3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_1_2_conv (Conv2D)        (None, 17, 17, 192)  258240      b7_7x7_1_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_4_conv (Conv2D)        (None, 17, 17, 192)  258240      b7_7x7_2_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_1_2_bn (BatchNormalizati (None, 17, 17, 192)  768         b7_7x7_1_2_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_4_bn (BatchNormalizati (None, 17, 17, 192)  768         b7_7x7_2_4_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_1_2 (Activation)         (None, 17, 17, 192)  0           b7_7x7_1_2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_4 (Activation)         (None, 17, 17, 192)  0           b7_7x7_2_4_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b7_1x1_conv (Conv2D)            (None, 17, 17, 192)  147648      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_1_3_conv (Conv2D)        (None, 17, 17, 192)  258240      b7_7x7_1_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_5_conv (Conv2D)        (None, 17, 17, 192)  258240      b7_7x7_2_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b7_pool_conv (Conv2D)           (None, 17, 17, 192)  147648      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "b7_1x1_bn (BatchNormalization)  (None, 17, 17, 192)  768         b7_1x1_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_1_3_bn (BatchNormalizati (None, 17, 17, 192)  768         b7_7x7_1_3_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_5_bn (BatchNormalizati (None, 17, 17, 192)  768         b7_7x7_2_5_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b7_pool_bn (BatchNormalization) (None, 17, 17, 192)  768         b7_pool_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b7_1x1 (Activation)             (None, 17, 17, 192)  0           b7_1x1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_1_3 (Activation)         (None, 17, 17, 192)  0           b7_7x7_1_3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b7_7x7_2_5 (Activation)         (None, 17, 17, 192)  0           b7_7x7_2_5_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b7_pool (Activation)            (None, 17, 17, 192)  0           b7_pool_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           b7_1x1[0][0]                     \n",
      "                                                                 b7_7x7_1_3[0][0]                 \n",
      "                                                                 b7_7x7_2_5[0][0]                 \n",
      "                                                                 b7_pool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b8_7x7_1_conv (Conv2D)          (None, 17, 17, 192)  147648      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b8_7x7_1_bn (BatchNormalization (None, 17, 17, 192)  768         b8_7x7_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b8_7x7_1 (Activation)           (None, 17, 17, 192)  0           b8_7x7_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b8_7x7_2_conv (Conv2D)          (None, 17, 17, 192)  258240      b8_7x7_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b8_7x7_2_bn (BatchNormalization (None, 17, 17, 192)  768         b8_7x7_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b8_7x7_2 (Activation)           (None, 17, 17, 192)  0           b8_7x7_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b8_3x3_1_conv (Conv2D)          (None, 17, 17, 192)  147648      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b8_7x7_3_conv (Conv2D)          (None, 17, 17, 192)  258240      b8_7x7_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b8_3x3_1_bn (BatchNormalization (None, 17, 17, 192)  768         b8_3x3_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b8_7x7_3_bn (BatchNormalization (None, 17, 17, 192)  768         b8_7x7_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b8_3x3_1 (Activation)           (None, 17, 17, 192)  0           b8_3x3_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b8_7x7_3 (Activation)           (None, 17, 17, 192)  0           b8_7x7_3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b8_3x3_2_conv (Conv2D)          (None, 8, 8, 320)    553280      b8_3x3_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b8_7x7_4_conv (Conv2D)          (None, 8, 8, 192)    331968      b8_7x7_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b8_3x3_2_bn (BatchNormalization (None, 8, 8, 320)    1280        b8_3x3_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b8_7x7_4_bn (BatchNormalization (None, 8, 8, 192)    768         b8_7x7_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b8_3x3_2 (Activation)           (None, 8, 8, 320)    0           b8_3x3_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b8_7x7_4 (Activation)           (None, 8, 8, 192)    0           b8_7x7_4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           b8_3x3_2[0][0]                   \n",
      "                                                                 b8_7x7_4[0][0]                   \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_2_1_conv (Conv2D)        (None, 8, 8, 448)    573888      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_2_1_bn (BatchNormalizati (None, 8, 8, 448)    1792        b9_3x3_2_1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_2_1 (Activation)         (None, 8, 8, 448)    0           b9_3x3_2_1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_1_conv (Conv2D)          (None, 8, 8, 384)    491904      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_2_2_conv (Conv2D)        (None, 8, 8, 384)    172416      b9_3x3_2_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_1_bn (BatchNormalization (None, 8, 8, 384)    1536        b9_3x3_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_2_2_bn (BatchNormalizati (None, 8, 8, 384)    1536        b9_3x3_2_2_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_1 (Activation)           (None, 8, 8, 384)    0           b9_3x3_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_2_2 (Activation)         (None, 8, 8, 384)    0           b9_3x3_2_2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_1_1_conv (Conv2D)        (None, 8, 8, 384)    442752      b9_3x3_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_1_2_conv (Conv2D)        (None, 8, 8, 384)    442752      b9_3x3_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_21_conv (Conv2D)         (None, 8, 8, 384)    442752      b9_3x3_2_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_22_conv (Conv2D)         (None, 8, 8, 384)    442752      b9_3x3_2_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b9_1x1_conv (Conv2D)            (None, 8, 8, 320)    409920      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_1_1_bn (BatchNormalizati (None, 8, 8, 384)    1536        b9_3x3_1_1_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_1_2_bn (BatchNormalizati (None, 8, 8, 384)    1536        b9_3x3_1_2_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_21_bn (BatchNormalizatio (None, 8, 8, 384)    1536        b9_3x3_21_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_22_bn (BatchNormalizatio (None, 8, 8, 384)    1536        b9_3x3_22_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "b9_pool_conv (Conv2D)           (None, 8, 8, 192)    245952      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "b9_1x1_bn (BatchNormalization)  (None, 8, 8, 320)    1280        b9_1x1_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_1_1 (Activation)         (None, 8, 8, 384)    0           b9_3x3_1_1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_1_2 (Activation)         (None, 8, 8, 384)    0           b9_3x3_1_2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_21 (Activation)          (None, 8, 8, 384)    0           b9_3x3_21_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b9_3x3_22 (Activation)          (None, 8, 8, 384)    0           b9_3x3_22_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b9_pool_bn (BatchNormalization) (None, 8, 8, 192)    768         b9_pool_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b9_1x1 (Activation)             (None, 8, 8, 320)    0           b9_1x1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1_0 (Concatenate)        (None, 8, 8, 768)    0           b9_3x3_1_1[0][0]                 \n",
      "                                                                 b9_3x3_1_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_2_0 (Concatenate)        (None, 8, 8, 768)    0           b9_3x3_21[0][0]                  \n",
      "                                                                 b9_3x3_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b9_pool (Activation)            (None, 8, 8, 192)    0           b9_pool_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           b9_1x1[0][0]                     \n",
      "                                                                 mixed9_1_0[0][0]                 \n",
      "                                                                 mixed9_2_0[0][0]                 \n",
      "                                                                 b9_pool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_2_1_conv (Conv2D)       (None, 8, 8, 448)    917952      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_2_1_bn (BatchNormalizat (None, 8, 8, 448)    1792        b10_3x3_2_1_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_2_1 (Activation)        (None, 8, 8, 448)    0           b10_3x3_2_1_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_1_conv (Conv2D)         (None, 8, 8, 384)    786816      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_2_2_conv (Conv2D)       (None, 8, 8, 384)    172416      b10_3x3_2_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_1_bn (BatchNormalizatio (None, 8, 8, 384)    1536        b10_3x3_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_2_2_bn (BatchNormalizat (None, 8, 8, 384)    1536        b10_3x3_2_2_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_1 (Activation)          (None, 8, 8, 384)    0           b10_3x3_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_2_2 (Activation)        (None, 8, 8, 384)    0           b10_3x3_2_2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_1_1_conv (Conv2D)       (None, 8, 8, 384)    442752      b10_3x3_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_1_2_conv (Conv2D)       (None, 8, 8, 384)    442752      b10_3x3_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_21_conv (Conv2D)        (None, 8, 8, 384)    442752      b10_3x3_2_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_22_conv (Conv2D)        (None, 8, 8, 384)    442752      b10_3x3_2_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b10_1x1_conv (Conv2D)           (None, 8, 8, 320)    655680      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_1_1_bn (BatchNormalizat (None, 8, 8, 384)    1536        b10_3x3_1_1_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_1_2_bn (BatchNormalizat (None, 8, 8, 384)    1536        b10_3x3_1_2_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_21_bn (BatchNormalizati (None, 8, 8, 384)    1536        b10_3x3_21_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_22_bn (BatchNormalizati (None, 8, 8, 384)    1536        b10_3x3_22_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b10_pool_conv (Conv2D)          (None, 8, 8, 192)    393408      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "b10_1x1_bn (BatchNormalization) (None, 8, 8, 320)    1280        b10_1x1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_1_1 (Activation)        (None, 8, 8, 384)    0           b10_3x3_1_1_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_1_2 (Activation)        (None, 8, 8, 384)    0           b10_3x3_1_2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_21 (Activation)         (None, 8, 8, 384)    0           b10_3x3_21_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b10_3x3_22 (Activation)         (None, 8, 8, 384)    0           b10_3x3_22_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b10_pool_bn (BatchNormalization (None, 8, 8, 192)    768         b10_pool_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b10_1x1 (Activation)            (None, 8, 8, 320)    0           b10_1x1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mixed10_1_1 (Concatenate)       (None, 8, 8, 768)    0           b10_3x3_1_1[0][0]                \n",
      "                                                                 b10_3x3_1_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "mixed10_2_1 (Concatenate)       (None, 8, 8, 768)    0           b10_3x3_21[0][0]                 \n",
      "                                                                 b10_3x3_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b10_pool (Activation)           (None, 8, 8, 192)    0           b10_pool_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           b10_1x1[0][0]                    \n",
      "                                                                 mixed10_1_1[0][0]                \n",
      "                                                                 mixed10_2_1[0][0]                \n",
      "                                                                 b10_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "g_avg_pool (GlobalAveragePoolin (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     g_avg_pool[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,360,056\n",
      "Trainable params: 20,327,064\n",
      "Non-trainable params: 32,992\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = inception()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以明顯發現到，Inception_v3也算的上是深，有十個block，但參數量只有2000萬，相比AlexNet的6000與VGG16的1億3千萬，真的是少太多。\n",
    "\n",
    "但Inception為模型的架構提出一個新的思維，不一定要關注深度，而還有寬，利用不同的大小的filter的堆疊，讓模型過程中自己決定要怎麼抽取出特徵。\n",
    "\n",
    "事貫上你可以發現，在Inception裡面有多處使用1x1的filter來做維度的降低，然後再做conv，這也某種方面的控制了參數量的發散，再加上最後不再採用fully connected layer而是global pooling，再次的減少參數量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "global average pooling或是global maxpooling的概念，就是單一filter上取平均或是最大值來做一個點，因此，最後一個block的output為8x8x2048會濃縮為2048個點，直接讓feature map來決定這個值，而不再利用fully connected layer做一次非線性計算，可以為最終的output做更直觀的理解。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
