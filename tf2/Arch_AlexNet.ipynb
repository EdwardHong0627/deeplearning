{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡開始已經假設你已經看過前面的所有基礎文件說明，因此多數註解會拿掉以維護版面乾淨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet是劃時代的一個重要作品，2012年橫空出世，讓整個電腦視覺的世界有了改變。後續的作品不少都受它影響。引入dropout、可視化第一層的filter，雙GPU、ReLU做為activation function、很深的神經網路...等。都是裡面的經典論述。不過裡面提到的Local Response Normalization在後續被證明沒有效果?因此後續就乏人問津了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下已有翻譯AlexNet論文，也可以參閱[相關文件](https://hackmd.io/@shaoeChen/SyjI6W2zB/https%3A%2F%2Fhackmd.io%2F%40shaoeChen%2FSJK_0YJmI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先載入相關需求套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定硬體資源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料集的部份是使用ImageNet訓練，不過這部份在下就只提供[資料集連結](http://www.image-net.org/)，不然硬train一發怕時間太久。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從論文中我們知道：\n",
    "* Alexnet的input dimension為224x224x3，從256x256的照片中隨機取得224x224的照片\n",
    "    * 這邊不知道是寫錯還是怎麼樣，input dimension為227x227的時候，其後續的dimension才會與論文上的架構圖相同\n",
    "* 過程中使用不少的資料增強的方式，這部份可以透過keras舊有的generator來達成，並不需要再自己實作一個，不過這取決你的建模方式\n",
    "* 他使用雙GPU訓練，不過現在隨便一張1080、2080系列的記憶體都不少，應該可以一張達成\n",
    "* 第一層用了非常大的filter size 11x11來進行卷積，並且利用比較大的stride來降低後面的資料維度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用標準的keras Sequential來建置模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(227, 227, 3)),   \n",
    "    tf.keras.layers.Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), padding='valid', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(5, 5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1000, activation='softmax')    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 62,378,344\n",
      "Trainable params: 62,378,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事實上，雖然AlexNet在目前來看好像是一個過氣的架構，但要注意到的是，不是新的架構就一定滿足你的資料集，這部份通常都是調整、調整、再調整才有辦法確定怎麼樣的架構適合怎麼樣的資料集，不要落入\"潮\"的思維陷井中。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
