{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow 2.0的一個重大變格在於預設模式為Eager Execution，這意味著我們不需要一定要在session的scope才能夠計算，但也不代表一定要像舊版本一樣的定義靜態圖才能使用靜態圖，在TensorFlow 2.0中提供`@tf.function`可以快速的達到這個需求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著下載MNIST資料集，在這之前先設置一個簡單的回傳資料的類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Loader:\n",
    "    def __init__(self):\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (self.x_train, self.y_train), (self.x_test, self.y_test) = mnist.load_data()\n",
    "        self.x_train = self.x_train = np.expand_dims(self.x_train / 255., -1)\n",
    "        self.x_test = self.x_test = np.expand_dims(self.x_test / 255., -1)\n",
    "    \n",
    "    def batch_data(self, t_type='train', batch_size=32):        \n",
    "        if t_type == 'train':\n",
    "            index = np.random.randint(0, self.x_train.shape[0], batch_size)\n",
    "            return self.x_train[index], self.y_train[index]\n",
    "        elif t_type == 'test':\n",
    "            index = np.random.randint(0, self.x_test.shape[0], batch_size)        \n",
    "            return self.x_test[index], self.y_test[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "簡單列印幾張照片來確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = Data_Loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "隨機取得10個索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x, y = data_loader.batch_data(batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 8, 4, 1, 4, 3, 5, 6, 0, 9], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx in range(10):\n",
    "    ax = plt.subplot(2, 5,idx+1)\n",
    "    ax.imshow(_x[idx, :, :, 0], cmap='gray')\n",
    "    plt.title(idx)    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定硬體資源，相關可[參考](https://hackmd.io/@shaoeChen/ryWIV4vkL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name=u'/physical_device:GPU:0', device_type=u'GPU'),\n",
       " PhysicalDevice(name=u'/physical_device:GPU:1', device_type=u'GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_visible_devices(devices=gpus[1], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(device=gpus[1], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "透過繼承`tf.keras.Model`來建構class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用`tf.keras.Model`建構類別的時候要注意三點：\n",
    "1. 初始化一定要繼承父類\n",
    "2. 是`call`不是`__call__`\n",
    "3. 不能使用`self.output`，因為這已經被用了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        # 一定要繼承父類的__init__才能使用父類相關的method與attribute\n",
    "        super(LeNet5, self).__init__()\n",
    "#         self.input = tf.keras.layers.InputLayer(input_shape=(28, 28, 1))\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), padding='valid', activation='tanh')\n",
    "        self.maxpool1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), padding='valid', activation='tanh')\n",
    "        self.maxpool2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(120, activation='tanh')\n",
    "        self.dense2 = tf.keras.layers.Dense(84, activation='tanh')\n",
    "        self.pred_y = tf.keras.layers.Dense(10, activation='softmax')\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.pred_y(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "編譯模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這邊不再使用原始keras所提供的高階api-`model.compile`、`model.fit`做訓練，而是自定義細部，下面定義方式取自官方的入門範例，並自行修改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為我們並未將label轉one-hot encoder，因此必需使用`sparse_categorical_crossentropy`做為loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先定義最佳化方式、損失函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義度量方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用`tf.GradientTape`訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 計算feedforward得到output\n",
    "        predictions = model(x)\n",
    "        # 計算實際與模型output的loss\n",
    "        loss = loss_object(y, predictions)\n",
    "    \n",
    "    # 計算可訓練參數對損失函數的梯度\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # 利用得到的梯度來更新參數\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer le_net5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "CPU times: user 35.2 s, sys: 1.74 s, total: 37 s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 迭代迴圈\n",
    "for epoch in range(5):\n",
    "    # 批次取資料迴圈\n",
    "    for batch in range(int(60000/128)):        \n",
    "        x, y = data_loader.batch_data(t_type='train', batch_size=128)\n",
    "        train_step(x, y)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在，調整上面的函數，加入裝飾器`@tf.function`之後再重新測試一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 計算feedforward得到output\n",
    "        predictions = model(x)\n",
    "        # 計算實際與模型output的loss\n",
    "        loss = loss_object(y, predictions)\n",
    "    \n",
    "    # 計算可訓練參數對損失函數的梯度\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # 利用得到的梯度來更新參數\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer le_net5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "CPU times: user 10.3 s, sys: 1.07 s, total: 11.4 s\n",
      "Wall time: 9.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 迭代迴圈\n",
    "for epoch in range(5):\n",
    "    # 批次取資料迴圈\n",
    "    for batch in range(int(60000/128)):        \n",
    "        x, y = data_loader.batch_data(t_type='train', batch_size=128)\n",
    "        train_step(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "轉為靜態圖之後的執行效率確實比Eager Execution還來的快吧。設置的方式也很簡單，只需要在求導的函數上加入裝飾器即可，其餘部份都沒有變更，相同方式也適用於其它的建模方式(如，繼承`tf.keras.Model`、Sequential、Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那究竟`@tf.function`做了什麼?它在第一次被呼叫的時候做了幾件事：  \n",
    "1. 每個`tf.`的方法都定義了計算節點，但沒有實質的計算\n",
    "2. 透過AutoGraph將函數內的Python控制流程表達式轉為TensorFlow計算圖中的對應節點，舉例來說，`while, for`變為`tf.while`，而`if`則變為`tf.cond`\n",
    "3. 基於上面兩個步驟，建立函數內程式碼的計算圖表示，為了確保圖的計算順序，圖中會自動加入`tf.control_dependcies`節點\n",
    "4. 執行一次計算圖\n",
    "5. 基於函數名稱與函數參數的類型生成一個hash value，將建立的計算圖寫入暫存hash table中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當`@tf.function`再次被執行的時候，會依據函數名稱以及該函數的參數類型計算hash vaule，確認是否已有暫存的計算圖，如果有就直接用，沒有的話就以上面的步驟重新計算一次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們利用一個簡單的範例來瞭解上面的說明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們定義一個很簡單的函數，裡面有python函數print，以及tf.print，就這樣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "    print('The function is running in Python')\n",
    "    tf.print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義兩個相同類型的變數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(1, dtype=tf.int32)\n",
    "b = tf.constant(2, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function is running in Python\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "f(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "f(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的範例可以發現到，這次沒有列印出文字，只有`tf.print`所列印的數值，因為第一次執行的時候做了幾件事：\n",
    "1. 將函數內的程式碼執行一次，因此列印文字說明\n",
    "2. 構建計算圖，並執行一次，因此列印出1。這個函數內就只有`tf.print`可以做為計算圖的節點，因此計算圖就只有這一個計算。\n",
    "3. 將這個計算圖暫存在hash table中，如果該函數有相同類型的參數，就會重覆使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "b_ = np.array(2, dtype=np.int32)\n",
    "f(b_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面雖然是numpy格式，但tensorflow會將numpy格式轉為tensorflow的tensor，因此是相同的類型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant(0.1, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function is running in Python\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "f(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的c是不同類型的數值，因此會再執行一次function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但要注意到的是，tensorflow只會將numpy格式轉為tensor，如果是單純的python object並不會，看下面的範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function is running in Python\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "f(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function is running in Python\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "f(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雖然1、2都是int，但這是python的格式，只有在相同值的情況下才會被視為是相同的參數格式，要特別注意。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "f(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面範例說明，在全域環境中定義一個`tf.Variable`，當它存在`@tf.function`內的時候，任何函數內的異動都會同時影響函式外部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(0.0)\n",
    "\n",
    "@tf.function\n",
    "def g():\n",
    "    a.assign(a + 1.0)\n",
    "    return a\n",
    "\n",
    "print(g())\n",
    "print(g())\n",
    "print(g())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "剛才說明了AutoGraph會轉換python流程為tensorflow流程，下面來看它的操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義一個簡單的函數，裡面有著python的if流程控制項"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def square_if_positive(x):\n",
    "    if x > 0:\n",
    "        x = x * x\n",
    "    else:\n",
    "        x = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(1)\n",
    "b = tf.constant(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(square_if_positive(a), square_if_positive(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__square_if_positive(x):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "  with ag__.FunctionScope('square_if_positive', 'square_if_positive_scope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as square_if_positive_scope:\n",
      "\n",
      "    def get_state():\n",
      "      return ()\n",
      "\n",
      "    def set_state(_):\n",
      "      pass\n",
      "\n",
      "    def if_true():\n",
      "      x_1, = x,\n",
      "      x_1 = x_1 * x_1\n",
      "      return x_1\n",
      "\n",
      "    def if_false():\n",
      "      x = 0\n",
      "      return x\n",
      "    cond = x > 0\n",
      "    x = ag__.if_stmt(cond, if_true, if_false, get_state, set_state, ('x',), ())\n",
      "    do_return = True\n",
      "    retval_ = square_if_positive_scope.mark_return_value(x)\n",
      "  do_return,\n",
      "  return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf.autograph.to_code(square_if_positive.python_function))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面我們發現到，流程控制項被轉換為`x = ag__.if_stmt(cond, if_true, if_false, get_state, set_state, ('x',), ())`這種圖計算的寫法。  \n",
    "\n",
    "AutoGraph有類似於編譯器的作用，將python的流程控制項轉為tensorflow的計算圖"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在實作上，如果是時間序列的結構，我們會需要將一系列的tensor以array的方式來存放做進一步處理，但在`@tf.function`內如果使用python的list是不行的，因此要使用`tf.TensorArray`來處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面表達式說明宣告一個大小為size，類型為dtype的TensorArray，如果設置`dynamic_size=True`，那它就會自動增長。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = tf.TensorArray(dtype, size, dynamic_size=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "寫入TensorArray，將value寫入索引index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(index, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取，讀取索引index的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表達式的寫法要注意：  \n",
    "* O: arr = arr.write(index, value)  \n",
    "* X: arr.write(index, value)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更多操作可參考[官方文件](https://www.tensorflow.org/api_docs/python/tf/TensorArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32) tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def array_write_and_read():\n",
    "    arr = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "    arr = arr.write(0, tf.constant(0.0))\n",
    "    arr = arr.write(1, tf.constant(1.0))\n",
    "    arr = arr.write(2, tf.constant(2.0))\n",
    "    arr_0 = arr.read(0)\n",
    "    arr_1 = arr.read(1)\n",
    "    arr_2 = arr.read(2)\n",
    "    return arr_0, arr_1, arr_2\n",
    "\n",
    "a, b, c = array_write_and_read()\n",
    "print(a, b, c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
