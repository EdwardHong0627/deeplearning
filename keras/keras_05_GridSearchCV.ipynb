{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  GridSearchCV\n",
    "## 說明\n",
    "模型參數很難得可以一次就取得最佳狀況，不少情況是需要做調參，如果一次一個參數跑完睡覺醒來再調一個，那中間或許就會浪費掉幾個小時的空檔了，這對急於取的成果的團隊來說是非常大的損失，Keras提供了與sklearn的接口，讓我們可以方便的透過sklearn的GridsearchCV來取得最佳參數，想當然爾，計算成本非常昂貴就是了。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "實作上會以[keras_dnn_Mnist](https://github.com/shaoeChen/deeplearning/blob/master/keras/keras_dnn_Mnist.ipynb)為範例來修正，加入GridsearchCV。\n",
    "\n",
    "註：為求版面簡潔，部份kears_dnn_Mnist說明會刪除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入需求套件\n",
    "* keras與sklearn的接口需載入`keras.wrappers.scikit_learn`內的`KerasClassifier`或`KerasRegression`\n",
    "    * 依實際需求載入分類或迴歸\n",
    "* sklearn需載入`sklearn.model_selection`的`GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "import pandas as pd\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此資料集為手寫辨識，若目錄底下沒有資料會重新下載，需要多點時間  \n",
    "下載之後檔案置於user\\\\.keras\\\\datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  keras自帶資料集\n",
    "from keras.datasets import mnist\n",
    "mnist_data = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入資料集後的第一件事是觀察你的資料集，舉凡訓練集、測試集樣本數，以及資料維度  \n",
    "我們可以發現，資料集是二值化之後的照片，所以維度為(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  index[0]為訓練資料集，index[1]為測試驗證資料集\n",
    "#  做資料賦值\n",
    "X_train_original, y_train_original = mnist_data[0]\n",
    "X_test_original, y_test_original = mnist_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train example: 60000\n",
      "train_data_shape: (60000, 28, 28)\n",
      "train_label_shape: (60000,)\n",
      "test_example: 10000\n",
      "test_data_shape: (10000, 28, 28)\n",
      "test_label_shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('train example:', X_train_original.shape[0])\n",
    "print('train_data_shape:', X_train_original.shape)\n",
    "print('train_label_shape:', y_train_original.shape)\n",
    "print('test_example:', X_test_original.shape[0])\n",
    "print('test_data_shape:', X_test_original.shape)\n",
    "print('test_label_shape:', y_test_original.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前我們的資料集為(m, pixel_x, pixel_y)，也就是(60000, 28, 28)，我們必需將照片pixel向量化(或稱flatten)，變成28\\*28=784，意指特徵n=784，m=60000。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  參數-1所指為剩下的，即28*28=784\n",
    "X_train_original.reshape(X_train_original.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_flatten = X_train_original.reshape(X_train_original.shape[0], -1)\n",
    "X_test_flatten = X_test_original.reshape(X_test_original.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料的處理通常都會做標準化來收縮資料分佈，在照片上最常見的處理方式就是除255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_flatten / 255\n",
    "X_test = X_test_flatten / 255\n",
    "X_train_non = X_train_flatten\n",
    "X_test_non = X_test_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  類別轉one-hot encoder\n",
    "y_train = np_utils.to_categorical(y_train_original, num_classes=10)\n",
    "y_test =  np_utils.to_categorical(y_test_original, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在調整之後記得確認資料維度是否正確，並且檢查label是否轉置正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature numbers: 60000\n",
      "train example: 784\n",
      "train_data_shape: (60000, 784)\n",
      "train_label_shape: (60000, 10)\n",
      "test_example: 784\n",
      "test_data_shape: (10000, 784)\n",
      "test_label_shape: (10000, 10)\n",
      "y_test: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "y_test_original: 2\n"
     ]
    }
   ],
   "source": [
    "print('feature numbers:', X_train.shape[0])\n",
    "print('train example:', X_train.shape[1])\n",
    "print('train_data_shape:', X_train.shape)\n",
    "print('train_label_shape:', y_train.shape)\n",
    "print('test_example:', X_test.shape[1])\n",
    "print('test_data_shape:', X_test.shape)\n",
    "print('test_label_shape:', y_test.shape)\n",
    "print('y_test:',y_test[1])\n",
    "print('y_test_original:', y_test_original[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前為止，我們的資料預處理已經完成，特徵數(n)=784，訓練樣本數=60000，測試樣本數=10000，預測類別=10(0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 實作模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們將model以function方式來實作，並將預計調參的部份透過function參數來傳遞，以最佳化函數為例，我們希望比較`adam`與`sgd`的差別，那就以function的參數來傳值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=392  #  輸出數量\n",
    "                    , activation='relu'  #  啟動函數\n",
    "                    , kernel_initializer='he_normal'  #  權重初始化方式\n",
    "                    , kernel_regularizer='l2'  #  正規化方式\n",
    "                    , input_shape=(784,)))  #  輸入維度，僅l=1層需要設置    \n",
    "    model.add(Dense(units=196  #  輸出數量，0-9\n",
    "                    , activation='relu'  #  啟動函數\n",
    "                    , kernel_initializer='he_normal'  #  權重初始化方式\n",
    "                    , kernel_regularizer='l2'))  #  正規化方式\n",
    "    model.add(Dense(units=98  #  輸出數量，0-9\n",
    "                    , activation='relu'  #  啟動函數\n",
    "                    , kernel_initializer='he_normal'  #  權重初始化方式\n",
    "                    , kernel_regularizer='l2'))  #  正規化方式\n",
    "    model.add(Dense(units=49  #  輸出數量，0-9\n",
    "                    , activation='relu'  #  啟動函數\n",
    "                    , kernel_initializer='he_normal'  #  權重初始化方式\n",
    "                    , kernel_regularizer='l2'))  #  正規化方式\n",
    "    model.add(Dense(units=10  #  輸出數量，0-9\n",
    "                    , activation='softmax'  #  啟動函數以softmax執行\n",
    "                    , kernel_initializer='he_normal'  #  權重初始化方式\n",
    "                    , kernel_regularizer='l2'))  #  正規化方式\n",
    "    model.compile(optimizer=optimizer\n",
    "                  , loss='categorical_crossentropy'\n",
    "                  , metrics=['accuracy'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下來，以`KerasClassifier`來實作一個模型，參數`build_fn`的來源即為剛才所建立的function。  \n",
    "verbose是否設置為1看個人需求，習慣上我會設置1，方便如果計算到崩潰之後還有點東西可以看，不過這部份還是可以配合keras的callback來寫入log。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=new_model, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設置超參數列表，格式需為dict  \n",
    "\n",
    "可利用batch_size與epochs來設置批次訓練數量與迭代次數  \n",
    "param_grid['batch_size']=[8]  \n",
    "param_grid['epochs']=[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid={}\n",
    "param_grid['optimizer']=['adam', 'sgd']\n",
    "param_grid['batch_size']=[8]  \n",
    "param_grid['epochs']=[2]  #  單純範例，所以設置兩次迭代"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "實作GridSearchCV，主要參數為`estimator`與`param_grid`  \n",
    "* estimator設置剛才所實作的KerasClassifier\n",
    "* param_grid設置剛才所建立的超參數列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] epochs=2, batch_size=8, optimizer=adam ..........................\n",
      "Epoch 1/2\n",
      "40000/40000 [==============================] - 71s 2ms/step - loss: 1.3549 - acc: 0.8569\n",
      "Epoch 2/2\n",
      "40000/40000 [==============================] - 67s 2ms/step - loss: 0.9526 - acc: 0.8892\n",
      "20000/20000 [==============================] - 8s 390us/step\n",
      "40000/40000 [==============================] - 16s 398us/step\n",
      "[CV]  epochs=2, batch_size=8, optimizer=adam, score=0.904500, total= 2.4min\n",
      "[CV] epochs=2, batch_size=8, optimizer=adam ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "40000/40000 [==============================] - 66s 2ms/step - loss: 1.3182 - acc: 0.8593\n",
      "Epoch 2/2\n",
      "40000/40000 [==============================] - 66s 2ms/step - loss: 0.9376 - acc: 0.8948\n",
      "20000/20000 [==============================] - 8s 389us/step\n",
      "40000/40000 [==============================] - 15s 385us/step\n",
      "[CV]  epochs=2, batch_size=8, optimizer=adam, score=0.884650, total= 2.3min\n",
      "[CV] epochs=2, batch_size=8, optimizer=adam ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "40000/40000 [==============================] - 65s 2ms/step - loss: 1.3526 - acc: 0.8595\n",
      "Epoch 2/2\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.9435 - acc: 0.8950\n",
      "20000/20000 [==============================] - 11s 572us/step\n",
      "40000/40000 [==============================] - 18s 443us/step\n",
      "[CV]  epochs=2, batch_size=8, optimizer=adam, score=0.908700, total= 2.5min\n",
      "[CV] epochs=2, batch_size=8, optimizer=sgd ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  8.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 5.8422 - acc: 0.8602\n",
      "Epoch 2/2\n",
      "40000/40000 [==============================] - 39s 984us/step - loss: 1.5635 - acc: 0.9108\n",
      "20000/20000 [==============================] - 7s 341us/step\n",
      "40000/40000 [==============================] - 13s 336us/step\n",
      "[CV]  epochs=2, batch_size=8, optimizer=sgd, score=0.915100, total= 1.6min\n",
      "[CV] epochs=2, batch_size=8, optimizer=sgd ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "40000/40000 [==============================] - 40s 988us/step - loss: 5.8626 - acc: 0.8629\n",
      "Epoch 2/2\n",
      "40000/40000 [==============================] - 39s 977us/step - loss: 1.5761 - acc: 0.9109\n",
      "20000/20000 [==============================] - 7s 355us/step\n",
      "40000/40000 [==============================] - 14s 357us/step\n",
      "[CV]  epochs=2, batch_size=8, optimizer=sgd, score=0.911450, total= 1.4min\n",
      "[CV] epochs=2, batch_size=8, optimizer=sgd ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "40000/40000 [==============================] - 39s 970us/step - loss: 5.8583 - acc: 0.8588\n",
      "Epoch 2/2\n",
      "40000/40000 [==============================] - 37s 933us/step - loss: 1.5638 - acc: 0.9085\n",
      "20000/20000 [==============================] - 7s 368us/step\n",
      "40000/40000 [==============================] - 14s 342us/step\n",
      "[CV]  epochs=2, batch_size=8, optimizer=sgd, score=0.916700, total= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 13.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 13.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 58s 961us/step - loss: 4.5157 - acc: 0.8799\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 58s 961us/step - loss: 1.0678 - acc: 0.9171\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=9)\n",
    "results = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回傳的物件內容豐富，可以研究下，針對結果可以利用pandas來呈現，以利判讀。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>param_epochs</th>\n",
       "      <th>param_optimizer</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136.629667</td>\n",
       "      <td>9.014000</td>\n",
       "      <td>0.899283</td>\n",
       "      <td>0.901358</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'epochs': 2, 'batch_size': 8, 'optimizer': 'a...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>0.906500</td>\n",
       "      <td>0.88465</td>\n",
       "      <td>0.888925</td>\n",
       "      <td>0.9087</td>\n",
       "      <td>0.908650</td>\n",
       "      <td>2.620398</td>\n",
       "      <td>1.719693</td>\n",
       "      <td>0.010488</td>\n",
       "      <td>0.008835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.703667</td>\n",
       "      <td>7.098333</td>\n",
       "      <td>0.914417</td>\n",
       "      <td>0.918400</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'epochs': 2, 'batch_size': 8, 'optimizer': 's...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.918175</td>\n",
       "      <td>0.91145</td>\n",
       "      <td>0.918450</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.918575</td>\n",
       "      <td>4.963884</td>\n",
       "      <td>0.219688</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0     136.629667         9.014000         0.899283          0.901358   \n",
       "1      81.703667         7.098333         0.914417          0.918400   \n",
       "\n",
       "  param_batch_size param_epochs param_optimizer  \\\n",
       "0                8            2            adam   \n",
       "1                8            2             sgd   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'epochs': 2, 'batch_size': 8, 'optimizer': 'a...                2   \n",
       "1  {'epochs': 2, 'batch_size': 8, 'optimizer': 's...                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0             0.9045            0.906500            0.88465   \n",
       "1             0.9151            0.918175            0.91145   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.888925             0.9087            0.908650      2.620398   \n",
       "1            0.918450             0.9167            0.918575      4.963884   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        1.719693        0.010488         0.008835  \n",
       "1        0.219688        0.002197         0.000167  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit_params\n",
    "keras的callback是在fit的時候給予相對應的參數，但是透過GridSearchCV要加入callback的時候似乎有點摸不著頭緒，下面範例提供參考，就不再執行了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  設置提早停止訓練的條件\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', min_delta=0., patience=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=9, fit_params={'callbacks': [early_stopping]})\n",
    "results = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結\n",
    "透過GridViewCV，我們可以將參數條列出來讓模型自動的將各排列組合訓練之後再來取最佳參數，但是需注意到記憶體用量，一但計算過程中崩潰，可能團隊也會跟著欲哭無淚，如果排列組合真的很多的話，記得搭配callback來做log記錄，或是checkpoint的記錄。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
